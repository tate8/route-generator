{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkDataset(torch_geometric.data.Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "    \n",
    "    @property\n",
    "    def file_names(self):\n",
    "        return glob.glob('data/*')\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(os.path.join(self.root, f'data_{idx}.pt'))\n",
    "        data.x = data.x.type(torch.float32)\n",
    "        data.edge_attr = data.edge_attr.type(torch.float32)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_features = torch_geometric.transforms.NormalizeFeatures(['edge_attr'])\n",
    "# transforms = torch_geometric.transforms.Compose([normalize_features])\n",
    "# dataset = NetworkDataset('data', transform=normalize_features)\n",
    "dataset = NetworkDataset('data')\n",
    "loader = torch_geometric.loader.DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__add__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_download',\n",
       " '_indices',\n",
       " '_infer_num_classes',\n",
       " '_is_protocol',\n",
       " '_process',\n",
       " 'download',\n",
       " 'file_names',\n",
       " 'get',\n",
       " 'get_summary',\n",
       " 'has_download',\n",
       " 'has_process',\n",
       " 'index_select',\n",
       " 'indices',\n",
       " 'len',\n",
       " 'log',\n",
       " 'num_classes',\n",
       " 'num_edge_features',\n",
       " 'num_features',\n",
       " 'num_node_features',\n",
       " 'pre_filter',\n",
       " 'pre_transform',\n",
       " 'print_summary',\n",
       " 'process',\n",
       " 'processed_dir',\n",
       " 'processed_file_names',\n",
       " 'processed_paths',\n",
       " 'raw_dir',\n",
       " 'raw_file_names',\n",
       " 'raw_paths',\n",
       " 'root',\n",
       " 'shuffle',\n",
       " 'to_datapipe',\n",
       " 'transform']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0719, -0.0214, -0.0346,  ...,  0.0399, -0.0074, -0.0208],\n",
       "        [ 0.0719, -0.0214, -0.0346,  ...,  0.0399, -0.0074, -0.0208],\n",
       "        [ 0.0719, -0.0214, -0.0346,  ...,  0.0399, -0.0074, -0.0208],\n",
       "        ...,\n",
       "        [ 0.0719, -0.0214, -0.0346,  ...,  0.0399, -0.0074, -0.0208],\n",
       "        [ 0.0719, -0.0214, -0.0346,  ...,  0.0399, -0.0074, -0.0208],\n",
       "        [ 0.0719, -0.0214, -0.0346,  ...,  0.0399, -0.0074, -0.0208]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Stage1Model(torch.nn.Module):\n",
    "    '''\n",
    "        Propagates graph data to current node and neighbors\n",
    "    '''\n",
    "    def __init__(self, out_embedding_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        nn1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dataset.num_edge_features, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, dataset.num_node_features*64),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        # conv1 gets edge information into the nodes\n",
    "        self.conv1 = torch_geometric.nn.conv.NNConv(dataset.num_node_features, 64, nn1)\n",
    "        # conv2 and conv3 work on the nodes only\n",
    "        self.conv2 = torch_geometric.nn.conv.GCNConv(64, 128)\n",
    "        self.conv3 = torch_geometric.nn.conv.GCNConv(128, 64)\n",
    "        self.attn = torch_geometric.nn.conv.GATv2Conv(64, out_embedding_dim, heads=3, concat=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, network_graph):\n",
    "        x, edge_index, edge_attr = network_graph.x, network_graph.edge_index, network_graph.edge_attr\n",
    "        \n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        out = self.attn(x, edge_index)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "test = Stage1Model(32)\n",
    "test(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000, 51.3322,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "        26.0617,  0.0000], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PreferenceEmbedder(torch.nn.Module):\n",
    "    '''\n",
    "        Embeds a (n_preferences, 1) user preference vector to a (embedding_dim, 1) vector\n",
    "    '''\n",
    "    def __init__(self, n_preferences, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.fclayer = torch.nn.Linear(n_preferences, embedding_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, user_preferences):\n",
    "        x = self.fclayer(user_preferences)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "data = dataset[0]\n",
    "test = PreferenceEmbedder(data.y.shape[0], 10)\n",
    "test(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([570])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Stage2Model(torch.nn.Module):\n",
    "    '''\n",
    "        Does final computations on available node choices and returns finalized choice scores\n",
    "    '''\n",
    "    def __init__(self, out_embedding_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch_geometric.nn.conv.GCNConv(in_channels=-1, \n",
    "                                                out_channels=64)\n",
    "        self.conv2 = torch_geometric.nn.conv.GCNConv(in_channels=64, \n",
    "                                                out_channels=64)\n",
    "        self.attn = torch_geometric.nn.conv.GATv2Conv(64, out_embedding_dim, heads=3, concat=False)\n",
    "    \n",
    "        self.softmax = torch.nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self, network_graph):\n",
    "        x, edge_index = network_graph.x, network_graph.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.attn(x, edge_index)\n",
    "        \n",
    "        x = torch.sum(x, dim=1)\n",
    "        scores = self.softmax(x)\n",
    "        return scores\n",
    "    \n",
    "test = Stage2Model(32)\n",
    "test(dataset[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGraphModel(torch.nn.Module):\n",
    "    '''\n",
    "        Stage 1 blocks -> mask/delete -> +preference embeddings -> stage 2 blocks -> out\n",
    "    '''\n",
    "    def __init__(self, Stage1Model, PreferenceEmbedder, Stage2Model):\n",
    "        super().__init__()\n",
    "        self.Stage1Model = Stage1Model\n",
    "        self.PreferenceEmbedder = PreferenceEmbedder\n",
    "        self.Stage2Model = Stage2Model\n",
    "    \n",
    "    # Masks all nodes and edges that are not connected to the current node.\n",
    "    # The current node is excluded.\n",
    "    def get_neighbor_graph(network_graph_propagated):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, network_graph, user_preferences):\n",
    "        network_graph_propagated = self.Stage1Model(network_graph)\n",
    "        \n",
    "        neighbor_graph = self.get_neighbor_graph(network_graph_propagated)\n",
    "        user_preferences_embedded = self.PreferenceEmbedder(user_preferences)\n",
    "        neighbor_graph_with_task_information = torch.add(neighbor_graph.x, user_preferences_embedded)\n",
    "        \n",
    "        out = self.Stage2Model(neighbor_graph_with_task_information)\n",
    "        return out\n",
    "\n",
    "stage_1_node_embedding_dim = 32\n",
    "stage_2_node_embedding_dim = 32\n",
    "\n",
    "stage1model = Stage1Model(stage_1_node_embedding_dim)\n",
    "preference_embedder = PreferenceEmbedder(data.y.shape[0], stage_1_node_embedding_dim)\n",
    "stage2model = Stage2Model(stage_2_node_embedding_dim)\n",
    "model = CustomGraphModel(stage1model, preference_embedder, stage2model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLFramework():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

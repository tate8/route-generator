{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gen import NetworkDatasetFactory\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "\n",
    "from IPython.display import IFrame\n",
    "import typing\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkDataset(torch_geometric.data.Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "    \n",
    "    @property\n",
    "    def file_names(self):\n",
    "        return glob.glob('data/*')\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(os.path.join(self.root, f'data_{idx}.pt'))\n",
    "        data.x = data.x.type(torch.float32)\n",
    "        data.edge_attr = data.edge_attr.type(torch.float32)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_features = torch_geometric.transforms.NormalizeFeatures(['edge_attr'])\n",
    "# transforms = torch_geometric.transforms.Compose([normalize_features])\n",
    "# dataset = NetworkDataset('data', transform=normalize_features)\n",
    "dataset = NetworkDataset('data')\n",
    "loader = torch_geometric.loader.DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0304,  0.0509, -0.0100,  ...,  0.0022, -0.0256,  0.0153],\n",
       "        [ 0.0304,  0.0509, -0.0100,  ...,  0.0022, -0.0256,  0.0153],\n",
       "        [ 0.0304,  0.0509, -0.0100,  ...,  0.0022, -0.0256,  0.0153],\n",
       "        ...,\n",
       "        [ 0.0304,  0.0509, -0.0100,  ...,  0.0022, -0.0256,  0.0153],\n",
       "        [ 0.0304,  0.0509, -0.0100,  ...,  0.0022, -0.0256,  0.0153],\n",
       "        [ 0.0304,  0.0509, -0.0100,  ...,  0.0022, -0.0256,  0.0153]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Stage1Model(torch.nn.Module):\n",
    "    '''\n",
    "        Propagates graph data to current node and neighbors\n",
    "    '''\n",
    "    def __init__(self, out_embedding_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        nn1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dataset.num_edge_features, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, dataset.num_node_features*64),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        # conv1 gets edge information into the nodes\n",
    "        self.conv1 = torch_geometric.nn.conv.NNConv(dataset.num_node_features, 64, nn1)\n",
    "        # conv2 and conv3 work on the nodes only\n",
    "        self.conv2 = torch_geometric.nn.conv.GCNConv(64, 128)\n",
    "        self.conv3 = torch_geometric.nn.conv.GCNConv(128, 64)\n",
    "        self.attn = torch_geometric.nn.conv.GATv2Conv(64, out_embedding_dim, heads=3, concat=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, network_graph):\n",
    "        x, edge_index, edge_attr = network_graph.x, network_graph.edge_index, network_graph.edge_attr\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = self.conv2(x, edge_index)        \n",
    "        x = self.conv3(x, edge_index)        \n",
    "        out = self.attn(x, edge_index)\n",
    "        return out\n",
    "    \n",
    "test = Stage1Model(32)\n",
    "test(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.4047,  0.0000,  9.6319,  0.0000, 13.3729,  0.0000, 57.3690, 69.8578,\n",
       "         0.0000,  0.0000], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PreferenceEmbedder(torch.nn.Module):\n",
    "    '''\n",
    "        Embeds a (n_preferences, 1) user preference vector to a (embedding_dim, 1) vector\n",
    "    '''\n",
    "    def __init__(self, n_preferences, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.fclayer = torch.nn.Linear(n_preferences, embedding_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, user_preferences):\n",
    "        x = self.fclayer(user_preferences)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "data = dataset[0]\n",
    "test = PreferenceEmbedder(data.y.shape[0], 10)\n",
    "test(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stage2Model(torch.nn.Module):\n",
    "    '''\n",
    "        Does final computations on available node choices and returns finalized choice scores\n",
    "    '''\n",
    "    def __init__(self, out_embedding_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch_geometric.nn.dense.DenseGCNConv(in_channels=-1, \n",
    "                                                out_channels=64)\n",
    "        self.conv2 = torch_geometric.nn.dense.DenseGCNConv(in_channels=64, \n",
    "                                                out_channels=64)\n",
    "        self.attn = torch_geometric.nn.dense.DenseGATConv(64, out_embedding_dim, heads=3, concat=False)\n",
    "    \n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, network_graph):\n",
    "        x, adj = network_graph.x, network_graph.adj\n",
    "        x = self.conv1(x, adj)\n",
    "        x = self.conv2(x, adj)\n",
    "        x = self.attn(x, adj)\n",
    "        \n",
    "        x = torch.sum(x, dim=-1)\n",
    "        scores = self.softmax(x)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomGraphModel(torch.nn.Module):\n",
    "    '''\n",
    "        Stage 1 blocks -> mask/delete -> +preference embeddings -> stage 2 blocks -> out\n",
    "    '''\n",
    "    def __init__(self, Stage1Model, PreferenceEmbedder, Stage2Model):\n",
    "        super().__init__()\n",
    "        self.Stage1Model = Stage1Model\n",
    "        self.PreferenceEmbedder = PreferenceEmbedder\n",
    "        self.Stage2Model = Stage2Model\n",
    "    \n",
    "    # creates a new graph with all nodes that are connected to the current node.\n",
    "    def get_neighbor_graph(self, network_graph, network_graph_propagated):\n",
    "        current_node_index = torch.squeeze(torch.nonzero(network_graph.x[:, -1]==1))\n",
    "        coo_indices_top = torch.nonzero(network_graph.edge_index[0]==current_node_index)[0]\n",
    "        coo_indices_bottom = torch.nonzero(network_graph.edge_index[1]==current_node_index)[0]\n",
    "        neighbors_1 = network_graph_propagated.edge_index[1][coo_indices_top]\n",
    "        neighbors_2 = network_graph_propagated.edge_index[0][coo_indices_bottom]\n",
    "        \n",
    "        indices = torch.unique(torch.cat((neighbors_1, neighbors_2)))\n",
    "        # remove current_node_index from indices if present\n",
    "        indices = indices[indices!=current_node_index]\n",
    "        current_node_neighbors = torch.index_select(network_graph_propagated.x, 0, indices)\n",
    "        # adjacency tensor will be all ones to denote fully connected\n",
    "        s = current_node_neighbors.shape[0]\n",
    "        adj = torch.ones((s, s))\n",
    "        \n",
    "        neighbor_graph = torch_geometric.data.Data(x=current_node_neighbors, adj=adj)\n",
    "        return neighbor_graph\n",
    "    \n",
    "    def forward(self, network_graph, user_preferences):\n",
    "        original_graph = torch_geometric.data.Data(x=network_graph.x, edge_index=network_graph.edge_index)\n",
    "        embedded_x = self.Stage1Model(network_graph)\n",
    "        network_graph_propagated = network_graph\n",
    "        network_graph_propagated.x = embedded_x\n",
    "        \n",
    "        neighbor_graph = self.get_neighbor_graph(original_graph, network_graph_propagated)\n",
    "        user_preferences_embedded = self.PreferenceEmbedder(user_preferences)\n",
    "        neighbor_graph.x = torch.add(neighbor_graph.x, user_preferences_embedded)\n",
    "        neighbor_graph_with_task_information = neighbor_graph\n",
    "        \n",
    "        out = self.Stage2Model(neighbor_graph_with_task_information)\n",
    "        return out\n",
    "\n",
    "stage_1_node_embedding_dim = 32\n",
    "stage_2_node_embedding_dim = 32\n",
    "\n",
    "stage1model = Stage1Model(stage_1_node_embedding_dim)\n",
    "preference_embedder = PreferenceEmbedder(data.y.shape[0], stage_1_node_embedding_dim)\n",
    "stage2model = Stage2Model(stage_2_node_embedding_dim)\n",
    "model = CustomGraphModel(stage1model, preference_embedder, stage2model)\n",
    "# for d in dataset:\n",
    "#     model(d, d.y)\n",
    "model(dataset[50], dataset[50].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEnv:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def setup_env_for_episode(self, plottable_graph, network_graph, user_preferences):\n",
    "        '''\n",
    "            Defines neccesary class variables for an episode. These variables are used for internal\n",
    "            or for graphing purposes.\n",
    "        '''\n",
    "        self.plottable_graph = plottable_graph\n",
    "        self.network_graph = network_graph\n",
    "        self.user_preferences = user_preferences\n",
    "        self.user_preference_overall_distance = user_preferences[0]\n",
    "        self.user_preference_steepness = user_preferences[1]\n",
    "        self.user_preference_surface_roughness = user_preferences[2]\n",
    "        \n",
    "        self.num_nodes = self.network_graph.x.shape[0]\n",
    "        self.num_steps = 0\n",
    "        \n",
    "        is_start_node_index = 0\n",
    "        current_node_index = torch.squeeze(torch.nonzero(self.network_graph.x[:, is_start_node_index]==1))\n",
    "        self.nodes_in_route_indices = [int(current_node_index.numpy())]\n",
    "    \n",
    "    def step(self, action):\n",
    "        '''\n",
    "            Changes the environment based on an action. The action is the index of\n",
    "            which node the model choose for the route to go through next. The network graph\n",
    "            is changed to update the current node, give the reward, check if episode done, etc.\n",
    "        '''\n",
    "        self.nodes_in_route_indices.append(int(action.numpy()))\n",
    "        is_end_node_index = 1\n",
    "        is_in_route_index = 2\n",
    "        is_current_node_index = 3\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        observation = None\n",
    "        info = None\n",
    "        \n",
    "        action_is_end_node = self.network_graph.x[action, is_end_node_index] == 1\n",
    "        if action_is_end_node:\n",
    "            terminated = True\n",
    "            \n",
    "        if self.num_steps >= self.num_nodes:\n",
    "            truncated = True\n",
    "        \n",
    "        # action is idx of next chosen node (new current node)\n",
    "        prev_current_node_index = torch.squeeze(torch.nonzero(self.network_graph.x[:, is_current_node_index]==1))\n",
    "        # update previous current node\n",
    "        self.network_graph.x[prev_current_node_index, is_current_node_index] = 0\n",
    "        # update new current node\n",
    "        trail_already_in_route = int(self.network_graph.x[action, is_in_route_index] == 1)\n",
    "        self.network_graph.x[action, is_current_node_index] = 1\n",
    "        self.network_graph.x[action, is_in_route_index] = 1\n",
    "        \n",
    "        \n",
    "        # get reward\n",
    "        reward = None\n",
    "        very_steep_grade = 25\n",
    "        num_surface_types_minus_one = 2\n",
    "        edge_distance_attr_index = 0\n",
    "        edge_surface_roughness_attr_index = 1\n",
    "        edge_steepness_attr_index = 2\n",
    "        if action_is_end_node:\n",
    "            # give total reward\n",
    "            nodes_in_route_indices = torch.nonzero(self.network_graph.x[is_in_route_index] == 1)\n",
    "            route_subgraph = self.network_graph.subgraph(nodes_in_route_indices)\n",
    "            edges_in_route = route_subgraph.edge_attr\n",
    "            \n",
    "            overall_distance_pr = 1 - abs(1 - (torch.sum(edges_in_route[:, edge_distance_attr_index]/self.user_preference_overall_distance)))\n",
    "            steepness_pr = 1 - abs((self.user_preference_steepness/100) - (torch.mean(edges_in_route[:, edge_steepness_attr_index]/very_steep)))\n",
    "            surface_roughness_pr = 1 - abs((self.user_preference_surface_roughness/100) - (torch.mean(edges_in_route[:, edge_surface_roughness_attr_index]/num_surface_types_minus_one)))\n",
    "            \n",
    "            reward = torch.mean(torch.tensor([overall_distance_pr, steepness_pr, surface_roughness_pr])) * 100\n",
    "        else:\n",
    "            # give intermediate reward\n",
    "            previous_current_node = self.network_graph.x[prev_current_node_index]\n",
    "            new_current_node = self.network_graph.x[action]\n",
    "            \n",
    "            connecting_edge_index = torch.squeeze(torch.nonzero(((self.network_graph.edge_index[0]==prev_current_node_index)&(self.network_graph.edge_index[1]==action))))\n",
    "            connecting_edge = self.network_graph.edge_attr[connecting_edge_index]\n",
    "            \n",
    "            overall_distance_pr = 1 - abs(1 - (connecting_edge[edge_distance_attr_index]/self.user_preference_overall_distance))\n",
    "            print(overall_distance_pr)\n",
    "            steepness_pr = 1 - abs((self.user_preference_steepness/100) - (connecting_edge[edge_steepness_attr_index]/very_steep))\n",
    "            print(steepness_pr)\n",
    "            surface_roughness_pr = 1 - abs((self.user_preference_surface_roughness/100) - (connecting_edge[edge_surface_roughness_attr_index]/num_surface_types_minus_one))\n",
    "            print(surface_roughness_pr)\n",
    "            reward = torch.mean(torch.tensor([overall_distance_pr, steepness_pr, surface_roughness_pr])) - trail_already_in_route\n",
    "            print(trail_already_in_route)\n",
    "            print(reward)\n",
    "    \n",
    "            \n",
    "        observation = self.network_graph\n",
    "        info = {}\n",
    "        return observation, reward, terminated, truncated, info\n",
    "        \n",
    "    def reset(self):\n",
    "        '''\n",
    "            Resets the environment for a new episode by resetting all class variables\n",
    "            and generating a new network graph.\n",
    "        '''\n",
    "        plottable_graph, random_network_graph = NetworkDatasetFactory().get_random_pyg_graph()\n",
    "        random_network_graph.x = random_network_graph.x.type(torch.float32)\n",
    "        random_network_graph.edge_attr = random_network_graph.edge_attr.type(torch.float32)\n",
    "        self.setup_env_for_episode(plottable_graph, random_network_graph, random_network_graph.y)\n",
    "        return self.network_graph, {}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(stage_1_node_embedding_dim, stage_2_node_embedding_dim):\n",
    "        stage1model = Stage1Model(stage_1_node_embedding_dim)\n",
    "        preference_embedder = PreferenceEmbedder(3, stage_1_node_embedding_dim)\n",
    "        stage2model = Stage2Model(stage_2_node_embedding_dim)\n",
    "        model = CustomGraphModel(stage1model, preference_embedder, stage2model)\n",
    "        return model\n",
    "    \n",
    "class Agent:\n",
    "    def __init__(self, model):\n",
    "        self.learning_rate = 1e-4\n",
    "        self.model = model\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.rewards = []\n",
    "        \n",
    "    def sample_action(self, observation):\n",
    "        '''Returns an action based on the policy and observation'''\n",
    "        \n",
    "        clone = observation.clone()\n",
    "        neighbor_scores = model(clone, clone.y)\n",
    "        top_neighbor_index = torch.argmax(neighbor_scores)\n",
    "        # FOR TESTING\n",
    "        top_neighbor_index = torch.randint(0, neighbor_scores.shape[-1], (1,))[0]\n",
    "        # need to figure out what node idx this is in terms of the entire graph\n",
    "        current_node_index = torch.squeeze(torch.nonzero(observation.x[:, -1]==1))\n",
    "        coo_indices_top = torch.nonzero(observation.edge_index[0]==current_node_index)[0]\n",
    "        coo_indices_bottom = torch.nonzero(observation.edge_index[1]==current_node_index)[0]\n",
    "        neighbors_1 = observation.edge_index[1][coo_indices_top]\n",
    "        neighbors_2 = observation.edge_index[0][coo_indices_bottom]\n",
    "        neighbor_indices = torch.unique(torch.cat((neighbors_1, neighbors_2)))\n",
    "        \n",
    "        top_index = neighbor_indices[top_neighbor_index]\n",
    "        top_action = top_index\n",
    "        return top_action\n",
    "    \n",
    "    def update(self):\n",
    "        '''Updates the policy network's weights.'''\n",
    "        # this is where the algorithm specifics come in...\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0001)\n",
      "tensor(-7.5700)\n",
      "tensor(0.5700)\n",
      "0\n",
      "tensor(-2.3333)\n"
     ]
    }
   ],
   "source": [
    "env = GraphEnv()\n",
    "observation, info = env.reset()\n",
    "agent = Agent(get_model(32, 32))\n",
    "\n",
    "def sample_and_step(observation):\n",
    "    action = agent.sample_action(observation)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    return obs\n",
    "    \n",
    "o1 = sample_and_step(observation)\n",
    "# o2 = sample_and_step(o1)\n",
    "# o3 = sample_and_step(o2)\n",
    "# o4 = sample_and_step(o3)\n",
    "# o5 = sample_and_step(o4)\n",
    "# o6 = sample_and_step(o5)\n",
    "# o7 = sample_and_step(o6)\n",
    "# o8 = sample_and_step(o7)\n",
    "# o9 = sample_and_step(o8)\n",
    "# o10 = sample_and_step(o9)\n",
    "# o11 = sample_and_step(o10)\n",
    "# o12 = sample_and_step(o11)\n",
    "# o13 = sample_and_step(o12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.nodes_in_route_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = list(env.plottable_graph.nodes())\n",
    "ox.plot_graph_route(env.plottable_graph, [node_list[i] for i in env.nodes_in_route_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, pyG = NetworkDatasetFactory().get_random_pyg_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = list(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_node = list(G.nodes())[0]\n",
    "destination_node = list(G.nodes())[-1]\n",
    "route = nx.shortest_path(G, origin_node, destination_node)\n",
    "ox.plot_graph_route(G, route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GraphEnv()\n",
    "\n",
    "for seed in [1, 2, 3, 5, 8]:  # Fibonacci seeds\n",
    "    # set seed\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Reinitialize agent every seed\n",
    "    agent = Agent(get_model(32, 32))\n",
    "    reward_over_episodes = []\n",
    "\n",
    "    for episode in range(total_num_episodes):\n",
    "        observation, info = env.reset()\n",
    "        \n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.sample_action(observation)\n",
    "\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            agent.rewards.append(reward)\n",
    "\n",
    "            done = terminated or truncated\n",
    "           \n",
    "        # TODO\n",
    "        reward_over_episodes.append(wrapped_env.return_queue[-1])\n",
    "        agent.update()\n",
    "        \n",
    "        if episode % 1000 == 0:\n",
    "            # TODO\n",
    "            avg_reward = int(np.mean(wrapped_env.return_queue))\n",
    "            print(\"Episode:\", episode, \"Average Reward:\", avg_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
